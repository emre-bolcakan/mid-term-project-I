{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "In this file, instructions how to approach the challenge can be found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to work on different types of Machine Learning problems:\n",
    "\n",
    "- **Regression Problem**: The goal is to predict delay of flights.\n",
    "- **(Stretch) Multiclass Classification**: If the plane was delayed, we will predict what type of delay it is (will be).\n",
    "- **(Stretch) Binary Classification**: The goal is to predict if the flight will be cancelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import ttest_1samp\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_squared_error \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('flights_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('flights_merged.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0, subset=['crs_elapsed_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fl_date</th>\n",
       "      <th>mkt_unique_carrier</th>\n",
       "      <th>branded_code_share</th>\n",
       "      <th>mkt_carrier</th>\n",
       "      <th>mkt_carrier_fl_num</th>\n",
       "      <th>op_unique_carrier</th>\n",
       "      <th>tail_num</th>\n",
       "      <th>op_carrier_fl_num</th>\n",
       "      <th>origin_airport_id</th>\n",
       "      <th>origin</th>\n",
       "      <th>...</th>\n",
       "      <th>distance</th>\n",
       "      <th>passengers</th>\n",
       "      <th>capacity</th>\n",
       "      <th>total_gallons</th>\n",
       "      <th>dep_delay</th>\n",
       "      <th>nas_delay</th>\n",
       "      <th>security_delay</th>\n",
       "      <th>late_aircraft_delay</th>\n",
       "      <th>weather_delay</th>\n",
       "      <th>carrier_delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA_CODESHARE</td>\n",
       "      <td>AA</td>\n",
       "      <td>5606</td>\n",
       "      <td>OH</td>\n",
       "      <td>N575NN</td>\n",
       "      <td>5606</td>\n",
       "      <td>13577</td>\n",
       "      <td>MYR</td>\n",
       "      <td>...</td>\n",
       "      <td>157.0</td>\n",
       "      <td>1325.400000</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.76087</td>\n",
       "      <td>3.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA_CODESHARE</td>\n",
       "      <td>AA</td>\n",
       "      <td>5243</td>\n",
       "      <td>OH</td>\n",
       "      <td>N591NN</td>\n",
       "      <td>5243</td>\n",
       "      <td>13577</td>\n",
       "      <td>MYR</td>\n",
       "      <td>...</td>\n",
       "      <td>157.0</td>\n",
       "      <td>1325.400000</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.76087</td>\n",
       "      <td>3.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA_CODESHARE</td>\n",
       "      <td>AA</td>\n",
       "      <td>5249</td>\n",
       "      <td>OH</td>\n",
       "      <td>N578NN</td>\n",
       "      <td>5249</td>\n",
       "      <td>13577</td>\n",
       "      <td>MYR</td>\n",
       "      <td>...</td>\n",
       "      <td>157.0</td>\n",
       "      <td>1325.400000</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.76087</td>\n",
       "      <td>3.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA_CODESHARE</td>\n",
       "      <td>AA</td>\n",
       "      <td>5261</td>\n",
       "      <td>OH</td>\n",
       "      <td>N584NN</td>\n",
       "      <td>5261</td>\n",
       "      <td>13577</td>\n",
       "      <td>MYR</td>\n",
       "      <td>...</td>\n",
       "      <td>157.0</td>\n",
       "      <td>1325.400000</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.76087</td>\n",
       "      <td>3.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA_CODESHARE</td>\n",
       "      <td>AA</td>\n",
       "      <td>5358</td>\n",
       "      <td>OH</td>\n",
       "      <td>N577NN</td>\n",
       "      <td>5358</td>\n",
       "      <td>13577</td>\n",
       "      <td>MYR</td>\n",
       "      <td>...</td>\n",
       "      <td>157.0</td>\n",
       "      <td>1325.400000</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.76087</td>\n",
       "      <td>3.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195291</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>F9</td>\n",
       "      <td>F9</td>\n",
       "      <td>F9</td>\n",
       "      <td>1445</td>\n",
       "      <td>F9</td>\n",
       "      <td>N919FR</td>\n",
       "      <td>1445</td>\n",
       "      <td>10397</td>\n",
       "      <td>ATL</td>\n",
       "      <td>...</td>\n",
       "      <td>874.0</td>\n",
       "      <td>1292.000000</td>\n",
       "      <td>196.0</td>\n",
       "      <td>2.353042e+07</td>\n",
       "      <td>74.00000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195292</th>\n",
       "      <td>2018-01-07</td>\n",
       "      <td>F9</td>\n",
       "      <td>F9</td>\n",
       "      <td>F9</td>\n",
       "      <td>1445</td>\n",
       "      <td>F9</td>\n",
       "      <td>N902FR</td>\n",
       "      <td>1445</td>\n",
       "      <td>10397</td>\n",
       "      <td>ATL</td>\n",
       "      <td>...</td>\n",
       "      <td>874.0</td>\n",
       "      <td>1292.000000</td>\n",
       "      <td>196.0</td>\n",
       "      <td>2.353042e+07</td>\n",
       "      <td>74.00000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195293</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>F9</td>\n",
       "      <td>F9</td>\n",
       "      <td>F9</td>\n",
       "      <td>1111</td>\n",
       "      <td>F9</td>\n",
       "      <td>N313FR</td>\n",
       "      <td>1111</td>\n",
       "      <td>12266</td>\n",
       "      <td>IAH</td>\n",
       "      <td>...</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>1324.333333</td>\n",
       "      <td>129.0</td>\n",
       "      <td>2.353042e+07</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195294</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>F9</td>\n",
       "      <td>F9</td>\n",
       "      <td>F9</td>\n",
       "      <td>1111</td>\n",
       "      <td>F9</td>\n",
       "      <td>N211FR</td>\n",
       "      <td>1111</td>\n",
       "      <td>12266</td>\n",
       "      <td>IAH</td>\n",
       "      <td>...</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>1324.333333</td>\n",
       "      <td>129.0</td>\n",
       "      <td>2.353042e+07</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195295</th>\n",
       "      <td>2018-01-07</td>\n",
       "      <td>F9</td>\n",
       "      <td>F9</td>\n",
       "      <td>F9</td>\n",
       "      <td>1111</td>\n",
       "      <td>F9</td>\n",
       "      <td>N223FR</td>\n",
       "      <td>1111</td>\n",
       "      <td>12266</td>\n",
       "      <td>IAH</td>\n",
       "      <td>...</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>1324.333333</td>\n",
       "      <td>129.0</td>\n",
       "      <td>2.353042e+07</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>191745 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           fl_date mkt_unique_carrier branded_code_share mkt_carrier  \\\n",
       "0       2019-01-01                 AA       AA_CODESHARE          AA   \n",
       "1       2019-01-01                 AA       AA_CODESHARE          AA   \n",
       "2       2019-01-01                 AA       AA_CODESHARE          AA   \n",
       "3       2019-01-01                 AA       AA_CODESHARE          AA   \n",
       "4       2019-01-01                 AA       AA_CODESHARE          AA   \n",
       "...            ...                ...                ...         ...   \n",
       "195291  2018-01-04                 F9                 F9          F9   \n",
       "195292  2018-01-07                 F9                 F9          F9   \n",
       "195293  2018-01-02                 F9                 F9          F9   \n",
       "195294  2018-01-04                 F9                 F9          F9   \n",
       "195295  2018-01-07                 F9                 F9          F9   \n",
       "\n",
       "        mkt_carrier_fl_num op_unique_carrier tail_num  op_carrier_fl_num  \\\n",
       "0                     5606                OH   N575NN               5606   \n",
       "1                     5243                OH   N591NN               5243   \n",
       "2                     5249                OH   N578NN               5249   \n",
       "3                     5261                OH   N584NN               5261   \n",
       "4                     5358                OH   N577NN               5358   \n",
       "...                    ...               ...      ...                ...   \n",
       "195291                1445                F9   N919FR               1445   \n",
       "195292                1445                F9   N902FR               1445   \n",
       "195293                1111                F9   N313FR               1111   \n",
       "195294                1111                F9   N211FR               1111   \n",
       "195295                1111                F9   N223FR               1111   \n",
       "\n",
       "        origin_airport_id origin  ... distance   passengers capacity  \\\n",
       "0                   13577    MYR  ...    157.0  1325.400000    157.0   \n",
       "1                   13577    MYR  ...    157.0  1325.400000    157.0   \n",
       "2                   13577    MYR  ...    157.0  1325.400000    157.0   \n",
       "3                   13577    MYR  ...    157.0  1325.400000    157.0   \n",
       "4                   13577    MYR  ...    157.0  1325.400000    157.0   \n",
       "...                   ...    ...  ...      ...          ...      ...   \n",
       "195291              10397    ATL  ...    874.0  1292.000000    196.0   \n",
       "195292              10397    ATL  ...    874.0  1292.000000    196.0   \n",
       "195293              12266    IAH  ...   1222.0  1324.333333    129.0   \n",
       "195294              12266    IAH  ...   1222.0  1324.333333    129.0   \n",
       "195295              12266    IAH  ...   1222.0  1324.333333    129.0   \n",
       "\n",
       "       total_gallons  dep_delay  nas_delay  security_delay  \\\n",
       "0       0.000000e+00    2.76087      3.875             0.0   \n",
       "1       0.000000e+00    2.76087      3.875             0.0   \n",
       "2       0.000000e+00    2.76087      3.875             0.0   \n",
       "3       0.000000e+00    2.76087      3.875             0.0   \n",
       "4       0.000000e+00    2.76087      3.875             0.0   \n",
       "...              ...        ...        ...             ...   \n",
       "195291  2.353042e+07   74.00000      2.000             0.0   \n",
       "195292  2.353042e+07   74.00000      2.000             0.0   \n",
       "195293  2.353042e+07    9.00000     20.000             0.0   \n",
       "195294  2.353042e+07    9.00000     20.000             0.0   \n",
       "195295  2.353042e+07    9.00000     20.000             0.0   \n",
       "\n",
       "        late_aircraft_delay  weather_delay  carrier_delay  \n",
       "0                      30.0            0.0            6.5  \n",
       "1                      30.0            0.0            6.5  \n",
       "2                      30.0            0.0            6.5  \n",
       "3                      30.0            0.0            6.5  \n",
       "4                      30.0            0.0            6.5  \n",
       "...                     ...            ...            ...  \n",
       "195291                 95.0            0.0           13.5  \n",
       "195292                 95.0            0.0           13.5  \n",
       "195293                  0.0            7.0            0.0  \n",
       "195294                  0.0            7.0            0.0  \n",
       "195295                  0.0            7.0            0.0  \n",
       "\n",
       "[191745 rows x 41 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= df['arr_delay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['arr_delay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.fl_date = X.fl_date.apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Task: Regression Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is **ARR_DELAY**. We need to be careful which columns to use and which don't. For example, DEP_DELAY is going to be the perfect predictor, but we can't use it because in real-life scenario, we want to predict the delay before the flight takes of --> We can use average delay from earlier days but not the one from the actual flight we predict.  \n",
    "\n",
    "For example, variables **CARRIER_DELAY, WEATHER_DELAY, NAS_DELAY, SECURITY_DELAY, LATE_AIRCRAFT_DELAY** shouldn't be used directly as predictors as well. However, we can create various transformations from earlier values.\n",
    "\n",
    "We will be evaluating your models by predicting the ARR_DELAY for all flights **1 week in advance**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering will play a crucial role in this problems. We have only very little attributes so we need to create some features that will have some predictive power.\n",
    "\n",
    "- weather: we can use some weather API to look for the weather in time of the scheduled departure and scheduled arrival.\n",
    "- statistics (avg, mean, median, std, min, max...): we can take a look at previous delays and compute descriptive statistics\n",
    "- airports encoding: we need to think about what to do with the airports and other categorical variables\n",
    "- time of the day: the delay probably depends on the airport traffic which varies during the day.\n",
    "- airport traffic\n",
    "- unsupervised learning as feature engineering?\n",
    "- **what are the additional options?**: Think about what we could do more to improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[['origin_airport_id', 'dest_airport_id', 'distance', 'passengers', 'crs_elapsed_time','capacity', 'total_gallons', 'dep_delay',\n",
    "       'nas_delay', 'security_delay', 'late_aircraft_delay',\n",
    "       'weather_delay', 'carrier_delay']]\n",
    "#dropped flight date :( "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_label = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(scaler.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, train_size=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection / Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to apply different selection techniques to find out which one will be the best for our problems.\n",
    "\n",
    "- Original Features vs. PCA conponents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use different ML techniques to predict each problem.\n",
    "\n",
    "- linear / logistic / multinomial logistic regression\n",
    "- Naive Bayes\n",
    "- Random Forest\n",
    "- SVM\n",
    "- XGBoost\n",
    "- The ensemble of your own choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dmatrix = xgb.DMatrix(data=X,label=y, enable_categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 7, alpha = 0.1,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07173831801102315"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07188307040310415"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    " # create regressor object\n",
    "regressor = RandomForestRegressor(n_estimators = 100)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the regressor with x and y data\n",
    "regressor.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 20.997776081386732\n",
      "Mean Squared Error: 1031.3092705195854\n",
      "Root Mean Squared Error: 32.11400427414161\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crs_elapsed_time       0.497925\n",
       "dep_delay              0.176867\n",
       "total_gallons          0.053538\n",
       "distance               0.040849\n",
       "nas_delay              0.036052\n",
       "carrier_delay          0.033856\n",
       "late_aircraft_delay    0.032412\n",
       "capacity               0.028833\n",
       "passengers             0.028475\n",
       "origin_airport_id      0.027593\n",
       "dest_airport_id        0.026465\n",
       "weather_delay          0.014511\n",
       "security_delay         0.002622\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance= pd.Series(regressor.feature_importances_, index= x_label).sort_values(ascending=False)\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators' : [100, 150, 200, 300], 'max_depth': [3, 10, 20, 30]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(regressor, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11898671987936302\n",
      "100\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(grid_result.best_score_)\n",
    "print( grid_result.best_params_['n_estimators'])\n",
    "print( grid_result.best_params_['max_depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 7, alpha = 0.1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have data from 2018 and 2019 to develop models. Use different evaluation metrics for each problem and compare the performance of different models.\n",
    "\n",
    "You are required to predict delays on **out of sample** data from **first 7 days (1st-7th) of January 2020** and to share the file with LighthouseLabs. Sample submission can be found in the file **_sample_submission.csv_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================\n",
    "## Stretch Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variables are **CARRIER_DELAY, WEATHER_DELAY, NAS_DELAY, SECURITY_DELAY, LATE_AIRCRAFT_DELAY**. We need to do additional transformations because these variables are not binary but continuos. For each flight that was delayed, we need to have one of these variables as 1 and others 0.\n",
    "\n",
    "It can happen that we have two types of delays with more than 0 minutes. In this case, take the bigger one as 1 and others as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is **CANCELLED**. The main problem here is going to be huge class imbalance. We have only very little cancelled flights with comparison to all flights. It is important to do the right sampling before training and to choose correct evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
